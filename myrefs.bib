
@article{ref1,
	title = {Pareto Set Learning for Multi-Objective Reinforcement Learning},
	volume = {39},
	rights = {Copyright (c) 2025 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/34068},
	doi = {10.1609/aaai.v39i18.34068},
	abstract = {Multi-objective decision-making problems have emerged in numerous real-world scenarios, such as video games, navigation and robotics. Considering the clear advantages of Reinforcement Learning ({RL}) in optimizing decision-making processes, researchers have delved into the development of Multi-Objective {RL} ({MORL}) methods for solving multi-objective decision problems. However, previous methods either cannot obtain the entire Pareto front, or employ only a single policy network for all the preferences over multiple objectives, which may not produce personalized solutions for each preference. To address these limitations, we propose a novel decomposition-based framework for {MORL}, Pareto Set Learning for {MORL} ({PSL}-{MORL}), that harnesses the generation capability of hypernetwork to produce the parameters of the policy network for each decomposition weight, generating relatively distinct policies for various scalarized subproblems with high efficiency. {PSL}-{MORL} is a general framework, which is compatible for any {RL} algorithm. The theoretical result guarantees the superiority of the model capacity of {PSL}-{MORL} and the optimality of the obtained policy network. Through extensive experiments on diverse benchmarks, we demonstrate the effectiveness of {PSL}-{MORL} in achieving dense coverage of the Pareto front, significantly outperforming state-of-the-art {MORL} methods in both the hypervolume and sparsity indicators.},
	pages = {18789--18797},
	number = {18},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Liu, Erlong and Wu, Yu-Chang and Huang, Xiaobin and Gao, Chengrui and Wang, Ren-Jian and Xue, Ke and Qian, Chao},
	urldate = {2025-05-27},
	date = {2025-04-11},
	langid = {english},
	note = {Number: 18},
	file = {Full Text PDF:C\:\\Users\\Elysium\\Zotero\\storage\\GNNFNEIC\\Liu 等 - 2025 - Pareto Set Learning for Multi-Objective Reinforcement Learning.pdf:application/pdf},
}

@article{ref2,
	title = {Stochastic Bayesian Optimization with Unknown Continuous Context Distribution via Kernel Density Estimation},
	volume = {38},
	rights = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/29158},
	doi = {10.1609/aaai.v38i11.29158},
	abstract = {Bayesian optimization ({BO}) is a sample-efficient method and has been widely used for optimizing expensive black-box functions. Recently, there has been a considerable interest in {BO} literature in optimizing functions that are affected by context variable in the environment, which is uncontrollable by decision makers. In this paper, we focus on the optimization of functions' expectations over continuous context variable, subject to an unknown distribution. To address this problem, we propose two algorithms that employ kernel density estimation to learn the probability density function ({PDF}) of continuous context variable online. The first algorithm is simpler, which directly optimizes the expectation under the estimated {PDF}. Considering that the estimated {PDF} may have high estimation error when the true distribution is complicated, we further propose the second algorithm that optimizes the distributionally robust objective. Theoretical results demonstrate that both algorithms have sub-linear Bayesian cumulative regret on the expectation objective. Furthermore, we conduct numerical experiments to empirically demonstrate the effectiveness of our algorithms.},
	pages = {12635--12643},
	number = {11},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Huang, Xiaobin and Song, Lei and Xue, Ke and Qian, Chao},
	urldate = {2025-05-27},
	date = {2024-03-24},
	langid = {english},
	note = {Number: 11},
	keywords = {{SO}: Non-convex Optimization},
	file = {Full Text PDF:C\:\\Users\\Elysium\\Zotero\\storage\\C8EZGABW\\Huang 等 - 2024 - Stochastic Bayesian Optimization with Unknown Continuous Context Distribution via Kernel Density Est.pdf:application/pdf},
}

@article{ref3,
	title = {Towards Running Time Analysis of Interactive Multi-Objective Evolutionary Algorithms},
	volume = {38},
	rights = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/30066},
	doi = {10.1609/aaai.v38i18.30066},
	abstract = {Evolutionary algorithms ({EAs}) are widely used for multi-objective optimization due to their population-based nature. Traditional multi-objective {EAs} ({MOEAs}) generate a large set of solutions to approximate the Pareto front, leaving a decision maker ({DM}) with the task of selecting a preferred solution. However, this process can be inefficient and time-consuming, especially when there are many objectives or the {DM} has subjective preferences. To address this issue, interactive {MOEAs} ({iMOEAs}) combine decision making into the optimization process, i.e., update the population with the help of the {DM}. In contrast to their wide applications, there has existed only two pieces of theoretical works on {iMOEAs}, which only considered interactive variants of the two simple single-objective algorithms, {RLS} and (1+1)-{EA}. This paper provides the first running time analysis (the essential theoretical aspect of {EAs}) for practical {iMOEAs}. Specifically, we prove that the expected running time of the well-developed interactive {NSGA}-{II} (called R-{NSGA}-{II}) for solving the {OneMinMax}, {OneJumpZeroJump} problems are all asymptotically faster than the traditional {NSGA}-{II}. Meanwhile, we present a variant of {OneMinMax}, and prove that R-{NSGA}-{II} can be exponentially slower than {NSGA}-{II}. These results provide theoretical justification for the effectiveness of {iMOEAs} while identifying situations where they may fail. Experiments are also conducted to validate the theoretical results.},
	pages = {20777--20785},
	number = {18},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Lu, Tianhao and Bian, Chao and Qian, Chao},
	urldate = {2025-05-27},
	date = {2024-03-24},
	langid = {english},
	note = {Number: 18},
	keywords = {{SO}: Evolutionary Computation},
	file = {Full Text PDF:C\:\\Users\\Elysium\\Zotero\\storage\\NCE2Q25E\\Lu 等 - 2024 - Towards Running Time Analysis of Interactive Multi-Objective Evolutionary Algorithms.pdf:application/pdf},
}
